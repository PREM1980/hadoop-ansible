---
# - name: Include OS-specific variables "{{ ansible_distribution }}-{{ ansible_distribution_version }}.
#   include_vars: "{{ ansible_os_family }}.yml"
#   when: ansible_distribution != 'Ubuntu' or ansible_distribution != 'Fedora'

# - name: Define java_packages.
#   set_fact:
#     java_packages: "{{ __java_packages | list }}"
#   when: java_packages is not defined

# # Setup/install tasks.
# - include: setup-RedHat.yml
#   when: ansible_os_family == 'RedHat'
#   static: no

# # Environment setup.
# - name: Set JAVA_HOME if configured.
#   template:
#     src: java_home.sh.j2
#     dest: /etc/profile.d/java_home.sh
#     mode: 0644
#   when: java_home is defined and java_home != ''

# - debug:
#     msg: "System {{ ansible_distribution }} has uuid {{ ansible_distribution_version }}"
# - group:
#     name: hadoop
#     state: present

# - name: Adding user  - {{ user }}  
#   user: name={{ user }}
#         group={{ group }}
#         shell=/bin/bash
#         password=${password}
#         groups=sudo
#         append=yes
#         generate_ssh_key=yes
#         ssh_key_bits=2048
#         ssh_key_file=.ssh/id_rsa

# - name: Set authorized key took from file
#   authorized_key: user=hduser key="{{ lookup('file', './files/authorized_keys.hduser.pub') }}"

# upload ssh key
# - authorized_key:
#     user: hduser
#     state: present
#     # manage_dir: yes
#     key: "{{ lookup('file', '/Users/prem/.ssh/id_rsa.pub') }}"
# # configure ssh server

# - name: Download hadoop
#   get_url: url={{ hadoop_download_url }} dest=/home/{{ hadoop_user }}/hadoop-2.7.1.tar.gz
#   environment: proxy_env

# - name: Extract hadoop archive
#   unarchive: src=/home/{{ hadoop_user }}/hadoop-2.7.1.tar.gz dest=/usr/local owner={{ hadoop_user}} group={{ hadoop_group }} creates=/usr/local/hadoop copy=no
  
# # this is an alternative for the local deployment where the hadoop binary can be cached locally
# #- name: unpack hadoop
# #  unarchive: src=/home/vagrant/src/roles/common/templates/hadoop-2.7.1.tar.gz dest=/usr/local owner={{ hadoop_user}} group={{ hadoop_group }} creates=/usr/local/hadoop

# - command: mv /usr/local/hadoop-2.7.1 /usr/local/hadoop creates=/usr/local/hadoop removes=/usr/local/hadoop-2.7.1

- name: create a group called hadoop
  group:
    name: hadoop
    state: present

- name: add user
  user:
    name: hduser
    comment: "Hadoop User"
    shell: /bin/bash
    groups: hadoop
    append: yes
    generate_ssh_key: yes
    ## run command 'mkpasswd --method=sha-512' to create your own encrypted password ##
    password: $6$FJCD6DfRWieE$XEb5U924ydsk8JW0bXhE1VWx5xs3hfQR/yla70Pi/GVdA37XJu36gpW2q3qm7DKJ9hGGuy.RYe6V3XvAa2cN7/
    # ssh_key_type: id_rsa
  register: newuser
- debug:
    var: newuser

- name: copy ssh key
  copy:
    src: /Users/prem/.ssh/id_rsa.pub
    dest: ~/.ssh/id_rsa.pub

- name: add authorized_key
  authorized_key:
    user: hduser
    state: present
    key: "{{ newuser.ssh_public_key }}"

- name: change ssh config
  template:
    src: ./files/ssh-setup.j2
    dest: /etc/ssh/sshd_config
    owner: root
    mode: '0600'
    validate: /usr/sbin/sshd -t -f %s
    backup: yes
# restart sshd
- service:
    name: ssh
    state: restarted

#Hadoop code download - move it to hadoop once completed
- name: Download hadoop code
  get_url:
    url: http://apache.osuosl.org/hadoop/core/hadoop-2.8.1/hadoop-2.8.1.tar.gz 
    dest: /home/hduser/hadoop-2.8.1.tar.gz
    mode: 0440    

- name: Unarchive a file that is already on the remote machine
  unarchive:
    src: /home/hduser/hadoop-2.8.1.tar.gz
    dest: /usr/local/ 
    creates: /usr/local/hadoop 
    owner: hduser 
    group: hadoop
    copy: no

- name: Check if the hadoop directory is already created(used during provisioning)
  stat: path=/usr/local/hadoop
  register: p
    

- name: Move hadoop version to hadoop folder
  command: mv /usr/local/hadoop-2.8.1 /usr/local/hadoop
  when: not p.stat.exists

# - name: change to hduser
#   shell: sudo su - hduser

- name: Setting 
  # become_user: hduser
  lineinfile: 
    dest: /home/hduser/.bashrc 
    line: 'export HADOOP_HOME=/usr/local/hadoop' 
    insertafter: 'EOF' 
    regexp: 'export HADOOP_HOME=/usr/local/hadoop' 
    state: present

- name: Adding the path in the bashrc files
  become_user: hduser
  become: yes
  lineinfile: 
    dest: /home/hduser/.bashrc 
    line:   'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' 
    insertafter: 'EOF' 
    regexp: 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' 
    state: present

- name: Adding the path in the bashrc files
  become_user: hduser
  become: yes
  lineinfile: 
    dest: /home/hduser/.bashrc 
    line:   'export PATH=$PATH:$HADOOP_HOME/bin' 
    insertafter: 'EOF' 
    regexp: 'export PATH=$PATH:$HADOOP_HOME/bin' 
    state: present

- name: print the bashrc file
  become_user: hduser
  become: yes
  shell: cat /home/hduser/.bashrc
  register: catvar
  args:
    executable: /bin/bash

- debug:
    var: catvar

- name: Source the bashrc file
  become_user: hduser
  become: yes
  shell: source /home/hduser/.bashrc;env
  register: sourcevar
  args:
    executable: /bin/bash

- debug:
    var: sourcevar


- name: create directory /app/hadoop/tmp
  file:
    path: /app/hadoop/tmp
    state: directory
    owner: hduser
    group: hadoop
    mode: 0750
    recurse: yes

- name: set core site xml
  template:
    src: ./files/core-site.j2
    dest: /usr/local/hadoop/etc/hadoop/core-site.xml
    owner: hduser
    group: hadoop
    
- name: set hdfs site xml
  template:
    src: ./files/hdfs-site.j2
    dest: /usr/local/hadoop/etc/hadoop/hdfs-site.xml
    owner: hduser
    group: hadoop
    
- name: set mapred site xml
  template:
    src: ./files/mapred-site.j2
    dest: /usr/local/hadoop/etc/hadoop/mapred-site.xml
    owner: hduser
    group: hadoop

- name: create directory /tmp/gutenberg
  file:
    path: /tmp/gutenberg
    state: directory
    owner: hduser
    group: hadoop
    mode: 0750
    recurse: yes

- name: Download the book content 
  get_url:
    url: http://apache.osuosl.org/hadoop/core/hadoop-2.8.1/hadoop-2.8.1.tar.gz 
    dest: /tmp/gutenberg
    owner: hduser
    group: hadoop


    
                        